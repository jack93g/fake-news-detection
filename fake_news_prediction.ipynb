{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fake news prediction**\n",
    "\n",
    "Now it's time to apply some ML algorithms to our data and try to make a model which can distinguish between fake and real news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('news_df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = news_df[news_df['classification'] == 'fake']\n",
    "real_df = news_df[news_df['classification'] == 'real']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the clasification column to an integer so the models can process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df[\"class\"] = 0\n",
    "real_df[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the two dfs into one df again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_removed_stopwords</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>headline_tokenized</th>\n",
       "      <th>headline_removed_stopwords</th>\n",
       "      <th>headline_lemmatized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>Wikileaks: Podesta Had Disturbing ‘Beyond Disc...</td>\n",
       "      <td>Baxter Dmitry</td>\n",
       "      <td>by Baxter Dmitry in News , US // 0 Comments  ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>by baxter dmitry in news us 0 comments a new ...</td>\n",
       "      <td>['by', 'baxter', 'dmitry', 'in', 'news', 'us',...</td>\n",
       "      <td>['baxter', 'dmitry', 'news', 'us', '0', 'comme...</td>\n",
       "      <td>['baxter', 'dmitry', 'news', 'u', '0', 'commen...</td>\n",
       "      <td>wikileaks podesta had disturbing beyond discip...</td>\n",
       "      <td>['wikileaks', 'podesta', 'had', 'disturbing', ...</td>\n",
       "      <td>['wikileaks', 'podesta', 'disturbing', 'beyond...</td>\n",
       "      <td>['wikileaks', 'podesta', 'disturbing', 'beyond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>Trump Elected As President – Risks And Opportu...</td>\n",
       "      <td>The Saker</td>\n",
       "      <td>13904 Views November 09, 2016 193 Comments Ana...</td>\n",
       "      <td>fake</td>\n",
       "      <td>13904 views november 09 2016 193 comments anal...</td>\n",
       "      <td>['13904', 'views', 'november', '09', '2016', '...</td>\n",
       "      <td>['13904', 'views', 'november', '09', '2016', '...</td>\n",
       "      <td>['13904', 'view', 'november', '09', '2016', '1...</td>\n",
       "      <td>trump elected as president risks and opportuni...</td>\n",
       "      <td>['trump', 'elected', 'as', 'president', 'risks...</td>\n",
       "      <td>['trump', 'elected', 'president', 'risks', 'op...</td>\n",
       "      <td>['trump', 'elected', 'president', 'risk', 'opp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>Break The Silence Or Support Self-Determinatio...</td>\n",
       "      <td>shorty</td>\n",
       "      <td>B y Danny Haiphong S yria is “the target of on...</td>\n",
       "      <td>fake</td>\n",
       "      <td>b y danny haiphong s yria is the target of one...</td>\n",
       "      <td>['b', 'y', 'danny', 'haiphong', 's', 'yria', '...</td>\n",
       "      <td>['b', 'danny', 'haiphong', 'yria', 'target', '...</td>\n",
       "      <td>['b', 'danny', 'haiphong', 'yria', 'target', '...</td>\n",
       "      <td>break the silence or support self determinatio...</td>\n",
       "      <td>['break', 'the', 'silence', 'or', 'support', '...</td>\n",
       "      <td>['break', 'silence', 'support', 'self', 'deter...</td>\n",
       "      <td>['break', 'silence', 'support', 'self', 'deter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>Re: Donald-Trump-Accepts-The-Nomination-Public...</td>\n",
       "      <td>Anton Ossa</td>\n",
       "      <td>Wilderness Survival Copyright © 2016 The Econo...</td>\n",
       "      <td>fake</td>\n",
       "      <td>wilderness survival copyright 2016 the economi...</td>\n",
       "      <td>['wilderness', 'survival', 'copyright', '2016'...</td>\n",
       "      <td>['wilderness', 'survival', 'copyright', '2016'...</td>\n",
       "      <td>['wilderness', 'survival', 'copyright', '2016'...</td>\n",
       "      <td>re donald trump accepts the nomination public ...</td>\n",
       "      <td>['re', 'donald', 'trump', 'accepts', 'the', 'n...</td>\n",
       "      <td>['donald', 'trump', 'accepts', 'nomination', '...</td>\n",
       "      <td>['donald', 'trump', 'accepts', 'nomination', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>Re: More Than 101 Million Working Age American...</td>\n",
       "      <td>peggie gor</td>\n",
       "      <td>More Than 101 Million Working Age Americans Do...</td>\n",
       "      <td>fake</td>\n",
       "      <td>more than 101 million working age americans do...</td>\n",
       "      <td>['more', 'than', '101', 'million', 'working', ...</td>\n",
       "      <td>['101', 'million', 'working', 'age', 'american...</td>\n",
       "      <td>['101', 'million', 'working', 'age', 'american...</td>\n",
       "      <td>re more than 101 million working age americans...</td>\n",
       "      <td>['re', 'more', 'than', '101', 'million', 'work...</td>\n",
       "      <td>['101', 'million', 'working', 'age', 'american...</td>\n",
       "      <td>['101', 'million', 'working', 'age', 'american...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7257</th>\n",
       "      <td>2020 Census Results Show Big Changes To Americ...</td>\n",
       "      <td>AllSides Headline Roundup</td>\n",
       "      <td>According to the 2020 United States Census, th...</td>\n",
       "      <td>real</td>\n",
       "      <td>according to the 2020 united states census the...</td>\n",
       "      <td>['according', 'to', 'the', '2020', 'united', '...</td>\n",
       "      <td>['according', '2020', 'united', 'states', 'cen...</td>\n",
       "      <td>['according', '2020', 'united', 'state', 'cens...</td>\n",
       "      <td>2020 census results show big changes to americ...</td>\n",
       "      <td>['2020', 'census', 'results', 'show', 'big', '...</td>\n",
       "      <td>['2020', 'census', 'results', 'show', 'big', '...</td>\n",
       "      <td>['2020', 'census', 'result', 'show', 'big', 'c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7258</th>\n",
       "      <td>Dems And Gop Strike Short-Term Deal On Debt, B...</td>\n",
       "      <td>AllSides Headline Roundup</td>\n",
       "      <td>Democrats and Republicans have reached a tempo...</td>\n",
       "      <td>real</td>\n",
       "      <td>democrats and republicans have reached a tempo...</td>\n",
       "      <td>['democrats', 'and', 'republicans', 'have', 'r...</td>\n",
       "      <td>['democrats', 'republicans', 'reached', 'tempo...</td>\n",
       "      <td>['democrat', 'republican', 'reached', 'tempora...</td>\n",
       "      <td>dems and gop strike short term deal on debt bu...</td>\n",
       "      <td>['dems', 'and', 'gop', 'strike', 'short', 'ter...</td>\n",
       "      <td>['dems', 'gop', 'strike', 'short', 'term', 'de...</td>\n",
       "      <td>['dems', 'gop', 'strike', 'short', 'term', 'de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>January 6 Committee Votes To Hold Steve Bannon...</td>\n",
       "      <td>AllSides Headline Roundup</td>\n",
       "      <td>On Tuesday evening, the House Committee invest...</td>\n",
       "      <td>real</td>\n",
       "      <td>on tuesday evening the house committee investi...</td>\n",
       "      <td>['on', 'tuesday', 'evening', 'the', 'house', '...</td>\n",
       "      <td>['tuesday', 'evening', 'house', 'committee', '...</td>\n",
       "      <td>['tuesday', 'evening', 'house', 'committee', '...</td>\n",
       "      <td>january 6 committee votes to hold steve bannon...</td>\n",
       "      <td>['january', '6', 'committee', 'votes', 'to', '...</td>\n",
       "      <td>['january', '6', 'committee', 'votes', 'hold',...</td>\n",
       "      <td>['january', '6', 'committee', 'vote', 'hold', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7260</th>\n",
       "      <td>Biden Picks Susan Rice To Lead Domestic Policy...</td>\n",
       "      <td>AllSides Headline Roundup</td>\n",
       "      <td>Statecertified 2020 presidential election winn...</td>\n",
       "      <td>real</td>\n",
       "      <td>statecertified 2020 presidential election winn...</td>\n",
       "      <td>['statecertified', '2020', 'presidential', 'el...</td>\n",
       "      <td>['statecertified', '2020', 'presidential', 'el...</td>\n",
       "      <td>['statecertified', '2020', 'presidential', 'el...</td>\n",
       "      <td>biden picks susan rice to lead domestic policy...</td>\n",
       "      <td>['biden', 'picks', 'susan', 'rice', 'to', 'lea...</td>\n",
       "      <td>['biden', 'picks', 'susan', 'rice', 'lead', 'd...</td>\n",
       "      <td>['biden', 'pick', 'susan', 'rice', 'lead', 'do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>Report Claims Gop Lawmakers, White House Staff...</td>\n",
       "      <td>AllSides Headline Roundup</td>\n",
       "      <td>A report from Rolling Stone (Left bias) claims...</td>\n",
       "      <td>real</td>\n",
       "      <td>a report from rolling stone left bias claims r...</td>\n",
       "      <td>['a', 'report', 'from', 'rolling', 'stone', 'l...</td>\n",
       "      <td>['report', 'rolling', 'stone', 'left', 'bias',...</td>\n",
       "      <td>['report', 'rolling', 'stone', 'left', 'bias',...</td>\n",
       "      <td>report claims gop lawmakers white house staff ...</td>\n",
       "      <td>['report', 'claims', 'gop', 'lawmakers', 'whit...</td>\n",
       "      <td>['report', 'claims', 'gop', 'lawmakers', 'whit...</td>\n",
       "      <td>['report', 'claim', 'gop', 'lawmaker', 'white'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14762 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  \\\n",
       "7262  Wikileaks: Podesta Had Disturbing ‘Beyond Disc...   \n",
       "7263  Trump Elected As President – Risks And Opportu...   \n",
       "7264  Break The Silence Or Support Self-Determinatio...   \n",
       "7265  Re: Donald-Trump-Accepts-The-Nomination-Public...   \n",
       "7266  Re: More Than 101 Million Working Age American...   \n",
       "...                                                 ...   \n",
       "7257  2020 Census Results Show Big Changes To Americ...   \n",
       "7258  Dems And Gop Strike Short-Term Deal On Debt, B...   \n",
       "7259  January 6 Committee Votes To Hold Steve Bannon...   \n",
       "7260  Biden Picks Susan Rice To Lead Domestic Policy...   \n",
       "7261  Report Claims Gop Lawmakers, White House Staff...   \n",
       "\n",
       "                         source  \\\n",
       "7262              Baxter Dmitry   \n",
       "7263                  The Saker   \n",
       "7264                     shorty   \n",
       "7265                 Anton Ossa   \n",
       "7266                 peggie gor   \n",
       "...                         ...   \n",
       "7257  AllSides Headline Roundup   \n",
       "7258  AllSides Headline Roundup   \n",
       "7259  AllSides Headline Roundup   \n",
       "7260  AllSides Headline Roundup   \n",
       "7261  AllSides Headline Roundup   \n",
       "\n",
       "                                                   text classification  \\\n",
       "7262   by Baxter Dmitry in News , US // 0 Comments  ...           fake   \n",
       "7263  13904 Views November 09, 2016 193 Comments Ana...           fake   \n",
       "7264  B y Danny Haiphong S yria is “the target of on...           fake   \n",
       "7265  Wilderness Survival Copyright © 2016 The Econo...           fake   \n",
       "7266  More Than 101 Million Working Age Americans Do...           fake   \n",
       "...                                                 ...            ...   \n",
       "7257  According to the 2020 United States Census, th...           real   \n",
       "7258  Democrats and Republicans have reached a tempo...           real   \n",
       "7259  On Tuesday evening, the House Committee invest...           real   \n",
       "7260  Statecertified 2020 presidential election winn...           real   \n",
       "7261  A report from Rolling Stone (Left bias) claims...           real   \n",
       "\n",
       "                                           text_cleaned  \\\n",
       "7262   by baxter dmitry in news us 0 comments a new ...   \n",
       "7263  13904 views november 09 2016 193 comments anal...   \n",
       "7264  b y danny haiphong s yria is the target of one...   \n",
       "7265  wilderness survival copyright 2016 the economi...   \n",
       "7266  more than 101 million working age americans do...   \n",
       "...                                                 ...   \n",
       "7257  according to the 2020 united states census the...   \n",
       "7258  democrats and republicans have reached a tempo...   \n",
       "7259  on tuesday evening the house committee investi...   \n",
       "7260  statecertified 2020 presidential election winn...   \n",
       "7261  a report from rolling stone left bias claims r...   \n",
       "\n",
       "                                         text_tokenized  \\\n",
       "7262  ['by', 'baxter', 'dmitry', 'in', 'news', 'us',...   \n",
       "7263  ['13904', 'views', 'november', '09', '2016', '...   \n",
       "7264  ['b', 'y', 'danny', 'haiphong', 's', 'yria', '...   \n",
       "7265  ['wilderness', 'survival', 'copyright', '2016'...   \n",
       "7266  ['more', 'than', '101', 'million', 'working', ...   \n",
       "...                                                 ...   \n",
       "7257  ['according', 'to', 'the', '2020', 'united', '...   \n",
       "7258  ['democrats', 'and', 'republicans', 'have', 'r...   \n",
       "7259  ['on', 'tuesday', 'evening', 'the', 'house', '...   \n",
       "7260  ['statecertified', '2020', 'presidential', 'el...   \n",
       "7261  ['a', 'report', 'from', 'rolling', 'stone', 'l...   \n",
       "\n",
       "                                 text_removed_stopwords  \\\n",
       "7262  ['baxter', 'dmitry', 'news', 'us', '0', 'comme...   \n",
       "7263  ['13904', 'views', 'november', '09', '2016', '...   \n",
       "7264  ['b', 'danny', 'haiphong', 'yria', 'target', '...   \n",
       "7265  ['wilderness', 'survival', 'copyright', '2016'...   \n",
       "7266  ['101', 'million', 'working', 'age', 'american...   \n",
       "...                                                 ...   \n",
       "7257  ['according', '2020', 'united', 'states', 'cen...   \n",
       "7258  ['democrats', 'republicans', 'reached', 'tempo...   \n",
       "7259  ['tuesday', 'evening', 'house', 'committee', '...   \n",
       "7260  ['statecertified', '2020', 'presidential', 'el...   \n",
       "7261  ['report', 'rolling', 'stone', 'left', 'bias',...   \n",
       "\n",
       "                                        text_lemmatized  \\\n",
       "7262  ['baxter', 'dmitry', 'news', 'u', '0', 'commen...   \n",
       "7263  ['13904', 'view', 'november', '09', '2016', '1...   \n",
       "7264  ['b', 'danny', 'haiphong', 'yria', 'target', '...   \n",
       "7265  ['wilderness', 'survival', 'copyright', '2016'...   \n",
       "7266  ['101', 'million', 'working', 'age', 'american...   \n",
       "...                                                 ...   \n",
       "7257  ['according', '2020', 'united', 'state', 'cens...   \n",
       "7258  ['democrat', 'republican', 'reached', 'tempora...   \n",
       "7259  ['tuesday', 'evening', 'house', 'committee', '...   \n",
       "7260  ['statecertified', '2020', 'presidential', 'el...   \n",
       "7261  ['report', 'rolling', 'stone', 'left', 'bias',...   \n",
       "\n",
       "                                       headline_cleaned  \\\n",
       "7262  wikileaks podesta had disturbing beyond discip...   \n",
       "7263  trump elected as president risks and opportuni...   \n",
       "7264  break the silence or support self determinatio...   \n",
       "7265  re donald trump accepts the nomination public ...   \n",
       "7266  re more than 101 million working age americans...   \n",
       "...                                                 ...   \n",
       "7257  2020 census results show big changes to americ...   \n",
       "7258  dems and gop strike short term deal on debt bu...   \n",
       "7259  january 6 committee votes to hold steve bannon...   \n",
       "7260  biden picks susan rice to lead domestic policy...   \n",
       "7261  report claims gop lawmakers white house staff ...   \n",
       "\n",
       "                                     headline_tokenized  \\\n",
       "7262  ['wikileaks', 'podesta', 'had', 'disturbing', ...   \n",
       "7263  ['trump', 'elected', 'as', 'president', 'risks...   \n",
       "7264  ['break', 'the', 'silence', 'or', 'support', '...   \n",
       "7265  ['re', 'donald', 'trump', 'accepts', 'the', 'n...   \n",
       "7266  ['re', 'more', 'than', '101', 'million', 'work...   \n",
       "...                                                 ...   \n",
       "7257  ['2020', 'census', 'results', 'show', 'big', '...   \n",
       "7258  ['dems', 'and', 'gop', 'strike', 'short', 'ter...   \n",
       "7259  ['january', '6', 'committee', 'votes', 'to', '...   \n",
       "7260  ['biden', 'picks', 'susan', 'rice', 'to', 'lea...   \n",
       "7261  ['report', 'claims', 'gop', 'lawmakers', 'whit...   \n",
       "\n",
       "                             headline_removed_stopwords  \\\n",
       "7262  ['wikileaks', 'podesta', 'disturbing', 'beyond...   \n",
       "7263  ['trump', 'elected', 'president', 'risks', 'op...   \n",
       "7264  ['break', 'silence', 'support', 'self', 'deter...   \n",
       "7265  ['donald', 'trump', 'accepts', 'nomination', '...   \n",
       "7266  ['101', 'million', 'working', 'age', 'american...   \n",
       "...                                                 ...   \n",
       "7257  ['2020', 'census', 'results', 'show', 'big', '...   \n",
       "7258  ['dems', 'gop', 'strike', 'short', 'term', 'de...   \n",
       "7259  ['january', '6', 'committee', 'votes', 'hold',...   \n",
       "7260  ['biden', 'picks', 'susan', 'rice', 'lead', 'd...   \n",
       "7261  ['report', 'claims', 'gop', 'lawmakers', 'whit...   \n",
       "\n",
       "                                    headline_lemmatized  class  \n",
       "7262  ['wikileaks', 'podesta', 'disturbing', 'beyond...      0  \n",
       "7263  ['trump', 'elected', 'president', 'risk', 'opp...      0  \n",
       "7264  ['break', 'silence', 'support', 'self', 'deter...      0  \n",
       "7265  ['donald', 'trump', 'accepts', 'nomination', '...      0  \n",
       "7266  ['101', 'million', 'working', 'age', 'american...      0  \n",
       "...                                                 ...    ...  \n",
       "7257  ['2020', 'census', 'result', 'show', 'big', 'c...      1  \n",
       "7258  ['dems', 'gop', 'strike', 'short', 'term', 'de...      1  \n",
       "7259  ['january', '6', 'committee', 'vote', 'hold', ...      1  \n",
       "7260  ['biden', 'pick', 'susan', 'rice', 'lead', 'do...      1  \n",
       "7261  ['report', 'claim', 'gop', 'lawmaker', 'white'...      1  \n",
       "\n",
       "[14762 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.concat([fake_df, real_df], axis =0 )\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the unecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop(columns=['headline', 'source', 'text', 'classification', \n",
    "'text_cleaned', 'text_tokenized', 'text_removed_stopwords', 'headline_cleaned', 'headline_tokenized', 'headline_removed_stopwords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly shuffle df and reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>headline_lemmatized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>['home', 'headline', 'world', 'news', 'fix', '...</td>\n",
       "      <td>['fix', 'nbc', 'affiliate', 'accidentally', 'p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>['syria', 'opposition', 'rejected', 'russiansp...</td>\n",
       "      <td>['syrian', 'opposition', 'reject', 'russia', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>['man', 'forecast', 'replace', 'cuban', 'presi...</td>\n",
       "      <td>['likely', 'successor', 'cuba', 'castro', 'rej...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10713</th>\n",
       "      <td>['bni', 'store', 'oct', '27', '2016', 'germany...</td>\n",
       "      <td>['germany', 'gang', 'syrian', 'muslim', 'boy',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12203</th>\n",
       "      <td>['know', 'various', 'governmental', 'instituti...</td>\n",
       "      <td>['breaking', 'official', 'china', 'government'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_lemmatized  \\\n",
       "7753   ['home', 'headline', 'world', 'news', 'fix', '...   \n",
       "3824   ['syria', 'opposition', 'rejected', 'russiansp...   \n",
       "1911   ['man', 'forecast', 'replace', 'cuban', 'presi...   \n",
       "10713  ['bni', 'store', 'oct', '27', '2016', 'germany...   \n",
       "12203  ['know', 'various', 'governmental', 'instituti...   \n",
       "\n",
       "                                     headline_lemmatized  class  \n",
       "7753   ['fix', 'nbc', 'affiliate', 'accidentally', 'p...      0  \n",
       "3824   ['syrian', 'opposition', 'reject', 'russia', '...      1  \n",
       "1911   ['likely', 'successor', 'cuba', 'castro', 'rej...      1  \n",
       "10713  ['germany', 'gang', 'syrian', 'muslim', 'boy',...      0  \n",
       "12203  ['breaking', 'official', 'china', 'government'...      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.sample(frac = 1)\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.reset_index(inplace = True)\n",
    "df_merged.drop([\"index\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>headline_lemmatized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['home', 'headline', 'world', 'news', 'fix', '...</td>\n",
       "      <td>['fix', 'nbc', 'affiliate', 'accidentally', 'p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['syria', 'opposition', 'rejected', 'russiansp...</td>\n",
       "      <td>['syrian', 'opposition', 'reject', 'russia', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['man', 'forecast', 'replace', 'cuban', 'presi...</td>\n",
       "      <td>['likely', 'successor', 'cuba', 'castro', 'rej...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['bni', 'store', 'oct', '27', '2016', 'germany...</td>\n",
       "      <td>['germany', 'gang', 'syrian', 'muslim', 'boy',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['know', 'various', 'governmental', 'instituti...</td>\n",
       "      <td>['breaking', 'official', 'china', 'government'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text_lemmatized  \\\n",
       "0  ['home', 'headline', 'world', 'news', 'fix', '...   \n",
       "1  ['syria', 'opposition', 'rejected', 'russiansp...   \n",
       "2  ['man', 'forecast', 'replace', 'cuban', 'presi...   \n",
       "3  ['bni', 'store', 'oct', '27', '2016', 'germany...   \n",
       "4  ['know', 'various', 'governmental', 'instituti...   \n",
       "\n",
       "                                 headline_lemmatized  class  \n",
       "0  ['fix', 'nbc', 'affiliate', 'accidentally', 'p...      0  \n",
       "1  ['syrian', 'opposition', 'reject', 'russia', '...      1  \n",
       "2  ['likely', 'successor', 'cuba', 'castro', 'rej...      1  \n",
       "3  ['germany', 'gang', 'syrian', 'muslim', 'boy',...      0  \n",
       "4  ['breaking', 'official', 'china', 'government'...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X/y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merged['text_lemmatized']\n",
    "y = df_merged['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to test some different ml algorithms\n",
    "- we will try logistic regression, decision tree & random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tester(X, y, stopwords=None):\n",
    "    \n",
    "    # test/train split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "    # vectorization: this maps the text to a corresponding vector of real numbers so that it can be processed by a ML algorithm\n",
    "\n",
    "    vectorization = TfidfVectorizer(stop_words=stopwords)\n",
    "    xv_train = vectorization.fit_transform(X_train)\n",
    "    xv_test = vectorization.transform(X_test)\n",
    "\n",
    "    # here are the parameters to test\n",
    "\n",
    "    log_reg_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n",
    "    dec_tree_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "    rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "\n",
    "    modelclasses = [\n",
    "        [\"log regression\", LogisticRegression, log_reg_params],\n",
    "        [\"decision tree\", DecisionTreeClassifier, dec_tree_params],\n",
    "        [\"random forest\", RandomForestClassifier, rand_for_params]\n",
    "    ]\n",
    "\n",
    "    # try out each model with the parameters give above and append to a list\n",
    "    \n",
    "    insights = []\n",
    "    for modelname, Model, params_list in modelclasses:\n",
    "        for params in params_list:\n",
    "            model = Model(**params)\n",
    "            model.fit(xv_train, y_train)\n",
    "            score = model.score(xv_test, y_test)\n",
    "            preds = model.predict(xv_test)\n",
    "            f1score = f1_score(y_test, preds)\n",
    "            cv_score = cross_val_score(model, xv_train, y_train, cv=5).mean()\n",
    "            insights.append((modelname, model, params, score, f1score, cv_score))\n",
    "\n",
    "    insights.sort(key=lambda x:x[-1], reverse=True)\n",
    "    for modelname, model, params, cv_score, score, f1score in insights:\n",
    "        print(modelname, params, 'cv_score:', round(cv_score, 4), 'accuracy_score:', round(score, 4), 'f1_score:', round(f1score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log regression {'C': 10} cv_score: 0.9646 accuracy_score: 0.9636 f1_score: 0.9589\n",
      "random forest {'criterion': 'entropy'} cv_score: 0.9467 accuracy_score: 0.9459 f1_score: 0.9455\n",
      "log regression {'C': 1} cv_score: 0.9499 accuracy_score: 0.9491 f1_score: 0.9455\n",
      "random forest {'criterion': 'gini'} cv_score: 0.9413 accuracy_score: 0.9402 f1_score: 0.9411\n",
      "log regression {'C': 0.1} cv_score: 0.928 accuracy_score: 0.9274 f1_score: 0.922\n",
      "log regression {'C': 0.01} cv_score: 0.9029 accuracy_score: 0.9014 f1_score: 0.9038\n",
      "decision tree {'criterion': 'entropy'} cv_score: 0.8948 accuracy_score: 0.8944 f1_score: 0.9012\n",
      "decision tree {'criterion': 'gini'} cv_score: 0.8977 accuracy_score: 0.8963 f1_score: 0.8999\n"
     ]
    }
   ],
   "source": [
    "model_tester(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to find out which features are most important in the random forest model\n",
    "\n",
    "- the scores are high so we could have overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_imp_features(X, y, Model):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "    vectorization = TfidfVectorizer()\n",
    "    xv_train = vectorization.fit_transform(X_train)\n",
    "    xv_test = vectorization.transform(X_test)\n",
    "\n",
    "    model = Model\n",
    "\n",
    "    model.fit(xv_train, y_train)\n",
    "\n",
    "    new_train_df = pd.DataFrame()\n",
    "    new_test_df = pd.DataFrame()\n",
    "\n",
    "    for i, col in enumerate(vectorization.get_feature_names()):\n",
    "        new_train_df[col] = pd.arrays.SparseArray(xv_train[:, i].toarray().ravel(), fill_value=0)\n",
    "    \n",
    "    for i, col in enumerate(vectorization.get_feature_names()):\n",
    "        new_test_df[col] = pd.arrays.SparseArray(xv_test[:, i].toarray().ravel(), fill_value=0) \n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(0,20): \n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]),new_train_df.iloc[:,indices[f]].name)\n",
    "\n",
    "    number_features_print = 10\n",
    "    height = [importances[indices[i]] for i in range(0,number_features_print)]\n",
    "    bars = [new_train_df.iloc[:,indices[x]].name for x in range(0,number_features_print)]\n",
    "\n",
    "\n",
    "    height.reverse()\n",
    "    bars.reverse()\n",
    "\n",
    "    y_pos = np.arange(len(bars))\n",
    " \n",
    "    #   Create horizontal bars\n",
    "    plt.barh(y_pos, height)\n",
    " \n",
    "    # Create names on the y-axis\n",
    "    plt.yticks(y_pos, bars)\n",
    "    plt.title('Top predictors',fontsize=19)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.ylabel('Word', fontsize = 16)\n",
    "    plt.xlabel('Random Forest Coefficient', fontsize = 16)\n",
    "    plt.figure(figsize=(13, 13))\n",
    "\n",
    "    # Show graphic\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-8d506a339e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_imp_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-6f51be00b490>\u001b[0m in \u001b[0;36mfind_imp_features\u001b[0;34m(X, y, Model)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnew_test_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxv_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     std = np.std([tree.feature_importances_ for tree in model.estimators_],\n\u001b[1;32m     22\u001b[0m              axis=0)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \"\"\"\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         all_importances = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "find_imp_features(X, y, RandomForestClassifier(criterion= 'entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log regression {'C': 10} cv_score: 0.9501 accuracy_score: 0.9491 f1_score: 0.9507\n",
      "log regression {'C': 1} cv_score: 0.9415 accuracy_score: 0.9406 f1_score: 0.9388\n",
      "random forest {'criterion': 'gini'} cv_score: 0.9354 accuracy_score: 0.9346 f1_score: 0.9309\n",
      "random forest {'criterion': 'entropy'} cv_score: 0.9336 accuracy_score: 0.9328 f1_score: 0.9297\n",
      "log regression {'C': 0.1} cv_score: 0.9147 accuracy_score: 0.9152 f1_score: 0.9113\n",
      "log regression {'C': 0.01} cv_score: 0.8923 accuracy_score: 0.8927 f1_score: 0.8907\n",
      "decision tree {'criterion': 'gini'} cv_score: 0.8636 accuracy_score: 0.8608 f1_score: 0.8646\n",
      "decision tree {'criterion': 'entropy'} cv_score: 0.8582 accuracy_score: 0.8559 f1_score: 0.8615\n"
     ]
    }
   ],
   "source": [
    "model_tester(X, y, stopwords=['2016', 'said', 'thursday', 'october', 'friday', 'know'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to print confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "plot_confusion_matrix(model, xv_test, y_test, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "576841b4f7799d251ae57aad53f0bddb5c298a2c04b91f5151e4f2b208165af8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
